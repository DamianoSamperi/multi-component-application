apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["list", "get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: pod-reader-binding
  namespace: default
subjects:
- kind: ServiceAccount
  name: default
  namespace: default
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
---
# --- STEP 1 SERVICE ---
apiVersion: v1
kind: Service
metadata:
  name: nn-step-0
spec:
  type: LoadBalancer           
  selector:
    app: nn-service
    step: "0"
  ports:
  - port: 5000
    targetPort: 5000
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pipeline-step-0
data:
  PIPELINE_CONFIG: |
    step_id: 0
    total_steps: 2
    steps:
      - type: "upscaling"
        params:
          model_path: "../models/models-DF2K"
          scale_factor: 2
          tta: false
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pipeline-step-1
data:
  PIPELINE_CONFIG: |
    step_id: 1
    total_steps: 2
    steps:
      - type: "detection"
        params:
          threshold: 0.5
---
# --- STEP 1 DEPLOYMENT ---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nn-step-0
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nn-service
      step: "0"
  template:
    metadata:
      labels:
        app: nn-service
        step: "0"
    spec:
      nodeSelector:
        kubernetes.io/hostname: nano92
      containers:
      - name: nn
        image: dami00/multicomponent_service
        imagePullPolicy: Always
        envFrom:
        - configMapRef:
            name: pipeline-step-0
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        ports:
        - containerPort: 5000
        resources:
          limits:
            nvidia.com/gpu.shared: 1
        volumeMounts:
        - mountPath: /usr/local/cuda
          name: cuda-volume
        - mountPath: /usr/lib/aarch64-linux-gnu
          name: lib-volume
      volumes:
      - name: cuda-volume
        hostPath:
          path: /usr/local/cuda
          type: Directory
      - name: lib-volume
        hostPath:
          path: /usr/lib/aarch64-linux-gnu
          type: Directory
---
# --- STEP 2 DEPLOYMENT ---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nn-step-1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nn-service
      step: "1"
  template:
    metadata:
      labels:
        app: nn-service
        step: "1"
    spec:
      nodeSelector:
        kubernetes.io/hostname: nano93
      containers:
      - name: nn
        image: dami00/multicomponent_service
        imagePullPolicy: Always
        envFrom:
        - configMapRef:
            name: pipeline-step-1
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        ports:
        - containerPort: 5000
        resources:
          limits:
            nvidia.com/gpu.shared: 1
        volumeMounts:
        - mountPath: /usr/local/cuda
          name: cuda-volume
        - mountPath: /usr/lib/aarch64-linux-gnu
          name: lib-volume
        - name: jetson-inference-volume
          mountPath: /jetson-inference
      volumes:
      - name: cuda-volume
        hostPath:
          path: /usr/local/cuda
          type: Directory
      - name: lib-volume
        hostPath:
          path: /usr/lib/aarch64-linux-gnu
          type: Directory
      - name: jetson-inference-volume
        hostPath:
          path: /home/administrator/jetson-inference
          type: Directory
---
# --- STEP 2 SERVICE ---
apiVersion: v1
kind: Service
metadata:
  name: nn-step-1
spec:
  selector:
    app: nn-service
    step: "1"
  ports:
  - port: 5000
    targetPort: 5000
